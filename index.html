<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Audio-Video Sync Measurement with Meters</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body { margin: 0; font-family: Arial, sans-serif; background-color: #222; color: #fff; }
    #videoContainer {
      position: relative;
      width: 100%;
      height: calc(100vh - 250px); /* Adjust for control panel height */
      background-color: #000;
    }
    #videoElement {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    #crosshair {
      position: absolute;
      top: 50%;
      left: 50%;
      width: 20px;
      height: 20px;
      margin-left: -10px;
      margin-top: -10px;
      border: 2px solid red;
      border-radius: 50%;
      pointer-events: none;
    }
    #controls {
      padding: 10px;
      background-color: #111;
    }
    #thresholds {
      display: flex;
      justify-content: space-around;
      margin-bottom: 10px;
    }
    .threshold-control {
      flex: 1;
      margin: 0 10px;
    }
    .threshold-control label {
      display: block;
      text-align: center;
      margin-bottom: 5px;
    }
    .threshold-control input[type="range"] {
      width: 100%;
    }
    #meters {
      display: flex;
      justify-content: space-around;
      margin-top: 10px;
    }
    .meter-container {
      flex: 1;
      margin: 0 10px;
      text-align: center;
    }
    .meter {
      width: 100%;
      height: 20px;
      background-color: #555;
      position: relative;
    }
    .meter-fill {
      height: 100%;
      background-color: lime;
      width: 0%;
    }
    .meter-threshold {
      position: absolute;
      top: -2px;
      width: 2px;
      height: 24px;
      background-color: red;
    }
    #deltaDisplay {
      text-align: center;
      font-size: 24px;
      margin-top: 10px;
    }
    #startButton {
      display: block;
      margin: 10px auto;
      padding: 10px 20px;
      font-size: 18px;
    }
    canvas {
      display: none; /* Hide canvas used for processing */
    }
  </style>
</head>
<body>

<div id="videoContainer">
  <video id="videoElement" autoplay playsinline muted></video>
  <canvas id="videoCanvas"></canvas>
  <div id="crosshair"></div>
</div>

<div id="controls">
  <div id="thresholds">
    <div class="threshold-control">
      <label for="brightnessThreshold">Brightness Threshold: <span id="brightnessValue">200</span></label>
      <input type="range" id="brightnessThreshold" min="0" max="255" value="200">
    </div>
    <div class="threshold-control">
      <label for="audioThreshold">Audio Threshold: <span id="audioValue">50</span></label>
      <input type="range" id="audioThreshold" min="0" max="100" value="50">
    </div>
  </div>
  <div id="meters">
    <div class="meter-container">
      <div>Brightness Level</div>
      <div class="meter" id="brightnessMeter">
        <div class="meter-fill" id="brightnessFill"></div>
        <div class="meter-threshold" id="brightnessMeterThreshold"></div>
      </div>
    </div>
    <div class="meter-container">
      <div>Audio Level</div>
      <div class="meter" id="audioMeter">
        <div class="meter-fill" id="audioFill"></div>
        <div class="meter-threshold" id="audioMeterThreshold"></div>
      </div>
    </div>
  </div>
  <button id="startButton">Start Measurement</button>
  <div id="deltaDisplay">Delta: -- ms</div>
</div>

<script>
  let videoElement = document.getElementById('videoElement');
  let videoCanvas = document.getElementById('videoCanvas');
  let videoContext = videoCanvas.getContext('2d');
  let crosshair = document.getElementById('crosshair');

  let brightnessThresholdInput = document.getElementById('brightnessThreshold');
  let audioThresholdInput = document.getElementById('audioThreshold');
  let brightnessValueDisplay = document.getElementById('brightnessValue');
  let audioValueDisplay = document.getElementById('audioValue');
  let deltaDisplay = document.getElementById('deltaDisplay');
  let startButton = document.getElementById('startButton');

  // Meters
  let brightnessMeterFill = document.getElementById('brightnessFill');
  let audioMeterFill = document.getElementById('audioFill');
  let brightnessMeterThreshold = document.getElementById('brightnessMeterThreshold');
  let audioMeterThreshold = document.getElementById('audioMeterThreshold');

  let brightnessThreshold = parseInt(brightnessThresholdInput.value);
  let audioThreshold = parseInt(audioThresholdInput.value);

  let audioContext;
  let analyser;
  let audioDataArray;

  let lastBrightnessEventTime = null;
  let lastAudioEventTime = null;

  let brightnessExceeded = false;
  let audioExceeded = false;

  let running = false;

  // Update threshold displays
  brightnessThresholdInput.addEventListener('input', () => {
    brightnessThreshold = parseInt(brightnessThresholdInput.value);
    brightnessValueDisplay.textContent = brightnessThreshold;
    updateBrightnessThresholdMeter();
  });

  audioThresholdInput.addEventListener('input', () => {
    audioThreshold = parseInt(audioThresholdInput.value);
    audioValueDisplay.textContent = audioThreshold;
    updateAudioThresholdMeter();
  });

  startButton.addEventListener('click', async () => {
    if (!running) {
      startButton.disabled = true;
      await startMeasurement();
      startButton.textContent = 'Stop Measurement';
      startButton.disabled = false;
      // Remove running = true; from here
    } else {
      stopMeasurement();
      startButton.textContent = 'Start Measurement';
      deltaDisplay.textContent = 'Delta: -- ms';
      running = false;
    }
  });

  function updateBrightnessThresholdMeter() {
    let meterWidth = document.getElementById('brightnessMeter').offsetWidth;
    brightnessMeterThreshold.style.left = (brightnessThreshold / 255) * meterWidth - 1 + 'px';
  }

  function updateAudioThresholdMeter() {
    let meterWidth = document.getElementById('audioMeter').offsetWidth;
    audioMeterThreshold.style.left = (audioThreshold / 100) * meterWidth - 1 + 'px';
  }

  async function startMeasurement() {
    try {
      // Access camera and microphone
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { exact: "environment" } }, // Use the rear camera
        audio: true
      });

      // Set up video
      videoElement.srcObject = stream;
      videoElement.muted = true; // Mute to prevent feedback

      // Set up audio processing
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      await audioContext.resume();
      const audioSource = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      audioDataArray = new Uint8Array(analyser.frequencyBinCount);
      audioSource.connect(analyser);

      // Initialize threshold meters
      updateBrightnessThresholdMeter();
      updateAudioThresholdMeter();

      // Set running to true before starting processing
      running = true;

      // Start processing frames
      processVideoFrame();
      processAudioFrame();
    } catch (error) {
      alert('Error accessing media devices: ' + error.message);
      console.error('Error accessing media devices:', error);
      startButton.textContent = 'Start Measurement';
      startButton.disabled = false;
      running = false;
    }
  }

  function stopMeasurement() {
    // Stop video stream
    if (videoElement.srcObject) {
      videoElement.srcObject.getTracks().forEach(track => track.stop());
      videoElement.srcObject = null;
    }
    // Close audio context
    if (audioContext && audioContext.state !== 'closed') {
      audioContext.close();
      audioContext = null;
    }
    running = false; // Ensure running is set to false
  }

let lastBrightnessThresholdCrossedTime = null;
let lastAudioThresholdCrossedTime = null;
let brightnessThresholdCrossed = false;
let audioThresholdCrossed = false;

function processVideoFrame() {
  if (!running) return;

  if (videoElement.readyState >= HTMLMediaElement.HAVE_ENOUGH_DATA) {
    videoCanvas.width = videoElement.videoWidth;
    videoCanvas.height = videoElement.videoHeight;
    videoContext.drawImage(videoElement, 0, 0, videoCanvas.width, videoCanvas.height);

    const sampleSize = 10;
    const centerX = videoCanvas.width / 2;
    const centerY = videoCanvas.height / 2;
    const imageData = videoContext.getImageData(centerX - sampleSize / 2, centerY - sampleSize / 2, sampleSize, sampleSize);
    const data = imageData.data;

    let totalBrightness = 0;
    for (let i = 0; i < data.length; i += 4) {
      const brightness = (data[i] + data[i + 1] + data[i + 2]) / 3;
      totalBrightness += brightness;
    }
    const avgBrightness = totalBrightness / (data.length / 4);
    let brightnessPercent = (avgBrightness / 255) * 100;
    brightnessMeterFill.style.width = brightnessPercent + '%';

    // Detect threshold crossing (from below to above)
    if (avgBrightness > brightnessThreshold && !brightnessThresholdCrossed) {
      lastBrightnessThresholdCrossedTime = performance.now();
      brightnessThresholdCrossed = true; // Mark threshold as crossed
      crosshair.style.borderColor = 'lime';
      setTimeout(() => {
        crosshair.style.borderColor = 'red';
      }, 200);
    }

    // Reset flag if brightness drops below threshold
    if (avgBrightness <= brightnessThreshold) {
      brightnessThresholdCrossed = false;
    }

    checkThresholdsAndCalculateDelta();
  }

  requestAnimationFrame(processVideoFrame);
}

function processAudioFrame() {
  if (!running) return;

  analyser.getByteFrequencyData(audioDataArray);
  const maxAmplitude = Math.max(...audioDataArray);
  const normalizedAmplitude = (maxAmplitude / 255) * 100;
  audioMeterFill.style.width = normalizedAmplitude + '%';

  // Detect threshold crossing (from below to above)
  if (normalizedAmplitude > audioThreshold && !audioThresholdCrossed) {
    lastAudioThresholdCrossedTime = performance.now();
    audioThresholdCrossed = true; // Mark threshold as crossed
    deltaDisplay.style.color = 'yellow';
    setTimeout(() => {
      deltaDisplay.style.color = '#fff';
    }, 200);
  }

  // Reset flag if audio drops below threshold
  if (normalizedAmplitude <= audioThreshold) {
    audioThresholdCrossed = false;
  }

  checkThresholdsAndCalculateDelta();

  requestAnimationFrame(processAudioFrame);
}

function checkThresholdsAndCalculateDelta() {
  if (lastBrightnessThresholdCrossedTime && lastAudioThresholdCrossedTime) {
    const delta = lastAudioThresholdCrossedTime - lastBrightnessThresholdCrossedTime;

    // Interpret the delta for user-friendly output
    if (Math.abs(delta) > 500) {
      // Avoid large sync flips; keep it stable by ignoring large differences
      return;
    }

    // Determine whether audio is ahead or behind
    if (delta > 0) {
      // Audio is ahead of video
      deltaDisplay.textContent = 'Audio is ' + delta.toFixed(2) + ' ms ahead of video';
    } else {
      // Video is ahead of audio (invert the delta)
      deltaDisplay.textContent = 'Audio is ' + Math.abs(delta.toFixed(2)) + ' ms behind video';
    }
  }
}

function calculateDelta() {
  if (lastBrightnessEventTime && lastAudioEventTime) {
    const delta = lastBrightnessEventTime - lastAudioEventTime;
    deltaDisplay.textContent = 'Delta: ' + delta.toFixed(2) + ' ms';
  }
}

  // Initialize threshold meters on page load
  updateBrightnessThresholdMeter();
  updateAudioThresholdMeter();
</script>

</body>
</html>